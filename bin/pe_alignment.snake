#!/usr/bin/env python
# vim: set ft=python.snakemake
""" The prealignment workflow to identify basic characteristics about SRA runs.

Zhenxia originally developed this workflow. The goal here is to use the data to
determine if the sample is really RNA-seq and strandedness.

"""
import os
import sys

import pandas as pd
from pymongo import MongoClient
from snakemake.logging import logger
from pathlib import Path

from lcdblib.snakemake import helpers
from lcdblib.utils import utils
from lcdblib.pandas.utils import cartesian_product

sys.path.insert(0, '../lib/python')
import ncbi_remap

# Setup tempdir to work with lscratch
TMPDIR = os.path.join('/lscratch', os.getenv('SLURM_JOBID'))
#TMPDIR = '/mnt/threeTB/centos_scratch'
shell.prefix("set -euo pipefail; export TMPDIR={};".format(TMPDIR))

# Set working dir
workdir: '.'

# import config
configfile: '../config/prealignment_config.yaml'

# Connect to mongodb
with open('.mongodb_host', 'r') as fh:
    mongo_client = MongoClient(host=fh.read().strip(), port=27022)
    db = mongo_client['sra2']
    remap = db['remap']

################################################################################
# Build Sample Table
################################################################################
with open('../data/312_sample_golden_set_2016-06-14.txt', 'r') as fh:
    golden = [x.strip() for x in fh.readlines()]

samples = remap.aggregate([
    {'$unwind': '$runs'},
    {
        '$match': {
            '$and': [
                {'runs.srr': {'$exists': 1}},
                {'runs.srr': {'$in': golden}},
                {'runs.pre_aln_flags': 'PE'},
                {'runs.pre_aln_flags': 'complete'}
            ]
        }
    },
    {'$group': {'_id': {'sample': '$runs.srr', 'experiment': '$_id'}}},
    {'$project': {'_id': 0, 'experiment': '$_id.experiment', 'sample': '$_id.sample'}},
    {'$sort': {'sample': 1}},
])

sample_table = pd.DataFrame(list(samples))

################################################################################
# Set up file naming patterns and targets
################################################################################

# Patterns
patterns = {
    'fastq_clean': {
        'r1': '../output/alignment/raw/{experiment}/{sample}/{sample}_1.clean.fastq.gz',
        'r2': '../output/alignment/raw/{experiment}/{sample}/{sample}_2.clean.fastq.gz',
    },
    'fastq_md5': '../output/alignment/raw/{experiment}/{sample}/{sample}.md5',
    'fastq_clean_count': {
        'r1': '../output/alignment/raw/{experiment}/{sample}/{sample}_1.clean.fastq.gz.libsize',
        'r2': '../output/alignment/raw/{experiment}/{sample}/{sample}_2.clean.fastq.gz.libsize',
    },
    'atropos': {
        'r1': '../output/alignment/raw/{experiment}/{sample}/{sample}_1.trim.clean.fastq.gz',
        'r2': '../output/alignment/raw/{experiment}/{sample}/{sample}_2.trim.clean.fastq.gz',
    },
    'fastq_atropos_count': {
        'r1': '../output/alignment/raw/{experiment}/{sample}/{sample}_1.trim.clean.fastq.gz.libsize',
        'r2': '../output/alignment/raw/{experiment}/{sample}/{sample}_2.trim.clean.fastq.gz.libsize',
    },
    'hisat2': {
        'splice_sites': '../output/known_splice_sites_r6-11.txt',
        'bam': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam',
    },
    'bai': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam.bai',
    'feature_counts': {
        'counts': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam.counts',
        'summary': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam.counts.summary',
    },
    'samtools_stats': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam.samtools.stats',
    'samtools_idxstats': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam.samtools.idxstats',
    'bamtools_stats': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam.bamtools.stats',
}

# Build target files
sample_table = cartesian_product(sample_table, {'strand': ['first', 'second']})
targets = helpers.fill_patterns(patterns, sample_table)


rule targets:
    input:
        utils.flatten(targets)


################################################################################
# Fuctions
################################################################################

# Find snakemake wrappers:
def wrapper_for(path):
    URI = '../lcdb-wf/wrappers/wrappers'
    return 'file:' + os.path.join(URI, path)


def get_strand(srr):
    """Check strandedsess."""
    flags = remap.find_one({'runs.srr': srr}, {'runs.$.pre_aln_flags': 1})['runs'][0]['pre_aln_flags']

    if 'first_strand' in flags:
        return 'first_strand'
    elif 'second_strand' in flags:
        return 'second_strand'
    else:
        return 'unstranded'


################################################################################
# FASTQ Pre-process
################################################################################
rule fastq_clean:
    output:
        r1=patterns['fastq_clean']['r1'],
        r2=patterns['fastq_clean']['r2'],
        md5=patterns['fastq_md5'],
    shell:
        'source activate ncbi_remap '
        '&& fastq-dump -O $TMPDIR --split-files --gzip {wildcards.sample} '
        '&& gunzip -c $TMPDIR/{wildcards.sample}_1.fastq.gz $TMPDIR/{wildcards.sample}_2.fastq.gz | md5sum > {output.md5}'
        '&& ./get_proper_read_pairs.sh $TMPDIR/{wildcards.sample}_1.fastq.gz $TMPDIR/{wildcards.sample}_2.fastq.gz $TMPDIR/{wildcards.sample}_1.clean.fastq.gz $TMPDIR/{wildcards.sample}_2.clean.fastq.gz '
        '&& cp $TMPDIR/{wildcards.sample}_1.clean.fastq.gz {output.r1} '
        '&& cp $TMPDIR/{wildcards.sample}_2.clean.fastq.gz {output.r2} '
        '&& rm $TMPDIR/{wildcards.sample}_1.fastq.gz $TMPDIR/{wildcards.sample}_2.fastq.gz '
        '&& rm $TMPDIR/{wildcards.sample}_1.clean.fastq.gz $TMPDIR/{wildcards.sample}_2.clean.fastq.gz '


rule atropos:
    input:
        R1=patterns['fastq_clean']['r1'],
        R2=patterns['fastq_clean']['r2']
    output:
        R1=patterns['atropos']['r1'],
        R2=patterns['atropos']['r2']
    params:
        extra='-a file:../data/adapters.fa -A file:../data/adapters.fa -q 20'
    log: patterns['atropos']['r1'] + '.log'
    threads: 8
    wrapper: wrapper_for('atropos')


rule fastq_count:
    input: '{prefix}.fastq.gz'
    output: '{prefix}.fastq.gz.libsize'
    shell: 'gunzip -c {input} | echo $((`wc -l`/4)) > {output}'


################################################################################
# Alignment
################################################################################
rule hisat2_splice_site:
    input: gtf=config['references']['dmel']['gtf']
    output: patterns['hisat2']['splice_sites']
    shell: "hisat2_extract_splice_sites.py {input.gtf} > {output}"


def _params_hisat2_fastq(wildcards):
    base = '--max-intronlen 300000 --known-splicesite-infile {input.splice_sites} '

    strand = get_strand(wildcards.sample)
    if strand == 'first_strand':
        return base + '--rna-strandness FR'
    elif strand == 'second_strand':
        return base + '--rna-strandness RF'
    else:
        return base


rule hisat2_fastq:
    input:
        index=config['references']['dmel']['hisat2'],
        splice_sites=patterns['hisat2']['splice_sites'],
        fastq=[rules.atropos.output.R1, rules.atropos.output.R2],
    output: bam=patterns['hisat2']['bam']
    threads: 8
    params:
        hisat2_extra=_params_hisat2_fastq,
        samtools_sort_extra='--threads 6 -l 9 -m 3G -T $TMPDIR/samtools_sort'
    log: patterns['hisat2']['bam'] + '.log'
    wrapper: wrapper_for('hisat2/align')


rule bai:
    input: bam='{prefix}.bam'
    output: bai='{prefix}.bam.bai'
    shell: """
    source activate ncbi_remap
    samtools index {input.bam}
    """


################################################################################
# Feature Counts
################################################################################
def _params_featurecounts(wildcards):
    """Determine strandedness and pass correct settings."""
    strand = get_strand(wildcards.sample)
    base = '-Q 20 --ignoreDup -p -P -C -J '

    if strand == 'first_strand':
        return base + '-s 1'
    elif strand == 'second_strand':
        return base + '-s 2'
    else:
        return base + '-s 0'


rule featurecounts:
    input:
        annotation=config['references']['dmel']['gtf'],
        bam=patterns['hisat2']['bam']
    output:
        counts=patterns['feature_counts']['counts'],
        summary=patterns['feature_counts']['summary']
    params: extra=_params_featurecounts
    threads: 4
    log: patterns['feature_counts']['counts'] + '.log'
    wrapper: wrapper_for('featurecounts')


################################################################################
# Stats
################################################################################
rule run_stats:
    input:
        bam=patterns['hisat2']['bam'],
        bai=patterns['bai'],
    output:
        samtools_stats=patterns['samtools_stats'],
        samtools_idxstats=patterns['samtools_idxstats'],
        bamtools_stats=patterns['bamtools_stats']
    shell:
        'source activate ncbi_remap '
        '&& BAM=$(mktemp --suffix=".bam") '
        '&& cp {input.bam} $BAM '
        '&& cp {input.bam}.bai $BAM.bai '
        '&& samtools stats $BAM > {output.samtools_stats} '
        '&& samtools idxstats $BAM > {output.samtools_idxstats} '
        '&& bamtools stats -in $BAM > {output.bamtools_stats} '
        '&& rm $BAM'
