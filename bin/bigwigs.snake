#!/usr/bin/env python
# vim: set ft=python.snakemake
import os
import sys

import pandas as pd
from pymongo import MongoClient

from snakemake.io import regex

from lcdblib.snakemake import helpers
from lcdblib.utils import utils
from lcdblib.pandas.utils import cartesian_product

sys.path.insert(0, '../lib/python')
import ncbi_remap

# Setup tempdir to work with lscratch
TMPDIR = os.path.join('/lscratch', os.getenv('SLURM_JOBID'))
shell.prefix("set -euo pipefail; export TMPDIR={};".format(TMPDIR))

# Set working dir
workdir: '../.bigwigs'

# import config
configfile: '../config/prealignment_config.yaml'

# Connect to mongodb
with open('../output/.mongodb_host', 'r') as fh:
    mongo_client = MongoClient(host=fh.read().strip(), port=27022)
    db = mongo_client['sra2']
    remap = db['remap']

################################################################################
# Build Sample Table
################################################################################
# Golden 312 test runs (312)
with open('../data/312_sample_golden_set_2016-06-14.txt', 'r') as fh:
    golden = [x.strip() for x in fh.readlines()]

# All SRRs that the Miegs analyzed (13495)
with open('../data/13495_runs_analyzed_by_mieg.txt', 'r') as fh:
    mieg = [x.strip() for x in fh.readlines()]

# modEncode SRRs (644)
with open('../data/modEncode_srrs.txt', 'r') as fh:
    modEncode = [x.strip() for x in fh.readlines() if x.strip() != 'SRR325179']

samples = remap.aggregate([
    {'$unwind': '$runs'},
    {
        '$match': {
            '$and': [
                {'runs.srr': {'$exists': 1}},
                {'runs.srr': {'$in': golden}},
                {'runs.pre_aln_flags': 'complete'}
            ]
        }
    },
    {'$group': {'_id': {'sample': '$runs.srr', 'experiment': '$_id'}}},
    {'$project': {'_id': 0, 'experiment': '$_id.experiment', 'sample': '$_id.sample'}},
    {'$sort': {'sample': 1}},
])
#{'runs.pre_aln_flags': 'PE'},

sample_table = pd.DataFrame(list(samples))

################################################################################
# Set up file naming patterns and targets
################################################################################

# Patterns
patterns = {
    'chromSizes_fb': '../output/dmel_r6-11.flybase.chromsizes',
    'bam': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam',
    'bai': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam.bai',
    'jcounts': '../output/alignment/raw/{experiment}/{sample}/{sample}.fq.bam.counts.jcounts',
    'bamCoverage': '../output/bigwigs/raw/{experiment}/{sample}/{sample}.fq.{strand}.bw',
    'bamCoverage_fb': '../output/bigwigs/raw/{experiment}/{sample}/{sample}.fq.flybase.{strand}.bw',
    'expBamCoverage': '../output/bigwigs/raw/{experiment}/{experiment}.{strand}.bw',
    'expBamCoverage_fb': '../output/bigwigs/raw/{experiment}/{experiment}.flybase.{strand}.bw',
    'golden': '../output/bigwigs/golden_312.{strand}.bw',
    'golden_fb': '../output/bigwigs/golden_312.flybase.{strand}.bw',
    'inverse_bed': '../output/bigwigs/inverse_exons_20bp.{strand}.bed',
    'unannotated_golden': '../output/bigwigs/golden_312.{strand}.unannotated.bw',
    'unannotated_golden_fb': '../output/bigwigs/golden_312.flybase.{strand}.unannotated.bw',
    'hub': '/data/fearjm/datashare/ncbi_remap/hubs/flybase_example_hub.txt',
    'fb_tgz': '/data/fearjm/datashare/ncbi_remap/flybase_example_tracks.tgz',
    'jcount': '../output/bigwigs/golden_312.jcount',
}


# Build target files
sample_table = cartesian_product(sample_table, {'strand': ['first', 'second']})
targets = helpers.fill_patterns(patterns, sample_table)

rule targets:
    input:
       targets['bamCoverage'],
       targets['bamCoverage_fb'],
       targets['expBamCoverage'],
       targets['expBamCoverage_fb'],
       targets['golden'],
       targets['golden_fb'],
       targets['unannotated_golden'],
       targets['unannotated_golden_fb'],
       targets['hub'],
       targets['jcount']


################################################################################
# Fuctions
################################################################################
# Find snakemake wrappers:
def wrapper_for(path):
    URI = '../lcdb-wf/wrappers/wrappers'
    return 'file:' + os.path.join(URI, path)


def get_strand(srr):
    """Check strandedsess."""
    flags = remap.find_one({'runs.srr': srr}, {'runs.$.pre_aln_flags': 1})['runs'][0]['pre_aln_flags']

    if 'first_strand' in flags:
        return 'first_strand'
    elif 'second_strand' in flags:
        return 'second_strand'
    else:
        return 'unstranded'


################################################################################
# Make Individual BedGraphs
################################################################################
def _param_bamCoverage(wildcards):
    """Get strand information from wildcards."""
    base = '--outFileFormat bedgraph --binSize 1 '
    if wildcards.strand == 'first':
        return base + '--filterRNAstrand forward'
    elif wildcards.strand == 'second':
        return base + '--filterRNAstrand reverse'


rule bamCoverage:
    input:
        bam=patterns['bam'],
        bai=patterns['bai']
    output: '../output/bigwigs/raw/{experiment}/{sample}/{sample}.fq.{strand,first|second}.bedgraph'
    params:
        extra=_param_bamCoverage
    threads: 8
    wrapper: wrapper_for('deeptools/bamCoverage')


def _convertBedGraphToBigWig(wildcards):
    if 'flybase' in wildcards.prefix:
        return targets['chromSizes_fb']
    else:
        return config['references']['dmel']['chromSizes']


rule convertBedGraphToBigWig:
    input:
        bedgraph='{prefix}.bedgraph',
        chromSizes=_convertBedGraphToBigWig
    output:
        bigwig='{prefix}.bw'
    conda: '../config/extra_env.yaml'
    shell:
        'export LC_COLLATE=C; '
        'tmpBg=`mktemp --suffix=.bedgraph` '
        '&& sort -k1,1 -k2,2n {input.bedgraph} > $tmpBg '
        '&& bedGraphToBigWig $tmpBg {input.chromSizes} {output.bigwig} '
        '&& rm $tmpBg '


################################################################################
# Merge Experiment BigWigs
################################################################################
def _input_expMerge(wildcards):
    sTable = sample_table[(sample_table['experiment'] == wildcards.experiment) & (sample_table['strand'] == wildcards.strand)].copy()
    return utils.flatten(helpers.fill_patterns(dict(bam=patterns['bamCoverage']), sTable))


rule expMerge:
    input: _input_expMerge
    output: bedgraph=temp('../output/bigwigs/raw/{experiment}/{experiment}.{strand,first|second}.bedgraph')
    conda: '../config/extra_env.yaml'
    shell:"""
    inputs=({input})
    if [ ${{#inputs[@]}} -gt 1 ]; then
        bigWigMerge {input} {output.bedgraph}
    else
        bigWigToBedGraph {input[0]} {output.bedgraph}
    fi
    """


def _allMerge(wildcards):
    inputs = []
    for fn in targets['bamCoverage']:
        if wildcards.strand in fn:
            inputs.append(fn)
    return inputs


rule allMerge_gold:
    input: _allMerge
    output: bedgraph=temp('../output/bigwigs/golden_312.{strand,first|second}.bedgraph')
    conda: '../config/extra_env.yaml'
    shell:"""
    inputs=({input})
    if [ ${{#inputs[@]}} -gt 1 ]; then
        bigWigMerge {input} {output.bedgraph}
    else
        bigWigToBedGraph {input[0]} {output.bedgraph}
    fi
    """


################################################################################
# Convert to Flybase
################################################################################
rule convertChromSizes:
    input: chromSizes=config['references']['dmel']['chromSizes']
    output: chromSizes=patterns['chromSizes_fb']
    run:
        from lcdblib.utils.chrom_convert import import_conversion
        mapper = import_conversion('UCSC', 'FlyBase')
        out = open(output.chromSizes, 'w')
        with open(input.chromSizes) as fh:
            for row in fh:
                chrom, size = row.strip().split()
                out.write('\t'.join([mapper[chrom], size]) + '\n')
        out.close()


rule convertFlybase_bamCoverage:
    input: bedgraph=patterns['bamCoverage'].replace('.bw', '.bedgraph')
    output: bedgraph=temp('../output/bigwigs/raw/{experiment}/{sample}/{sample}.fq.flybase.{strand,first|second}.bedgraph')
    conda: '../config/extra_env.yaml'
    shell:"""
    chrom_convert --from UCSC --to FlyBase --fileType BED -i {input.bedgraph} -o {output.bedgraph}
    """


rule convertFlybase_expBamCoverage:
    input: bedgraph=patterns['expBamCoverage'].replace('.bw', '.bedgraph')
    output: bedgraph=temp('../output/bigwigs/raw/{experiment}/{experiment}.flybase.{strand,first|second}.bedgraph')
    conda: '../config/extra_env.yaml'
    shell:"""
    chrom_convert --from UCSC --to FlyBase --fileType BED -i {input.bedgraph} -o {output.bedgraph}
    """


rule convertFlybase_golden:
    input: bedgraph=patterns['golden'].replace('.bw', '.bedgraph')
    output: bedgraph=temp('../output/bigwigs/golden_312.flybase.{strand,first|second}.bedgraph')
    conda: '../config/extra_env.yaml'
    shell:"""
    chrom_convert --from UCSC --to FlyBase --fileType BED -i {input.bedgraph} -o {output.bedgraph}
    """


rule convertFlybase_unannotated:
    input: bedgraph=patterns['unannotated_golden'].replace('.bw', '.bedgraph')
    output: bedgraph=temp('../output/bigwigs/golden_312.flybase.{strand,first|second}.unannotated.bedgraph')
    conda: '../config/extra_env.yaml'
    shell:"""
    chrom_convert --from UCSC --to FlyBase --fileType BED -i {input.bedgraph} -o {output.bedgraph}
    """


################################################################################
# Create Diff BedGraphs
################################################################################
rule create_inverse_bed:
    input:
        gtf=config['references']['dmel']['gtf'],
        chromSizes=config['references']['dmel']['chromSizes']
    output:
        plus=patterns['inverse_bed'].format(strand='first'),
        minus=patterns['inverse_bed'].format(strand='second')
    run:
        import pybedtools

        # Import GTF
        gtf = pybedtools.BedTool(input.gtf).remove_invalid().sort().saveas()

        # Subset functions for pybedtools
        def featuretype_filter(feature, featuretype):
            if feature[2] == featuretype:
                return True
            return False

        def subset_featuretypes(g, featuretype):
            result = g.filter(featuretype_filter, featuretype).saveas()
            return pybedtools.BedTool(result.fn)

        def strand_filter(feature, strand):
            if feature[3] == strand:
                return True
            return False

        def subset_strand(g, strand):
            result = g.filter(strand_filter, strand).saveas()
            return pybedtools.BedTool(result.fn)

        # pull out all exons
        exons = subset_featuretypes(gtf, 'exon').bed6()

        # Merge overlapping regions strand specifically
        merged = exons.sort().merge(s=True, bed=True)

        # Extend features by 20bp
        extended = merged.slop( g=input.chromSizes, b=20)

        # split by strand
        exons_plus = pybedtools.BedTool([x[:3] for x in subset_strand(extended, '+')])
        exons_minus = pybedtools.BedTool([x[:3] for x in subset_strand(extended, '-')])

        pybedtools.BedTool([x[:3] + ['.', '.', '+'] for x in exons_plus.sort().complement(g=input.chromSizes)]).saveas(output.plus)
        pybedtools.BedTool([x[:3] + ['.', '.', '-'] for x in exons_minus.sort().complement(g=input.chromSizes)]).saveas(output.minus)


rule unannotated_golden:
    input:
        bedgraph=patterns['golden'].replace('.bw', '.bedgraph'),
        bed=patterns['inverse_bed']
    output:
        bedgraph=temp('../output/bigwigs/golden_312.{strand,first|second}.unannotated.bedgraph')
    run:
        import pybedtools

        if wildcards.strand == 'first':
            strand = '+'
        else:
            strand = '-'

        bg = pybedtools.BedTool([x[:4] + ['.', strand] for x in pybedtools.BedTool(input.bedgraph)])
        bed = pybedtools.BedTool(input.bed)
        pybedtools.BedTool([x[:4] for x in bg.intersect(bed, s=True)]).saveas(output.bedgraph)


################################################################################
# Create Track Hub
################################################################################
def _trackhub_individual(wildcards):
    pat = dict(bc=patterns['bamCoverage'])
    first_st = sample_table[sample_table['strand'] == 'first']
    first = helpers.fill_patterns(pat, first_st)['bc']
    return list(first)


rule trackhub:
    input:
        individual=_trackhub_individual,
        golden=patterns['golden'].format(strand='first'),
        unannotated_golden=patterns['unannotated_golden'].format(strand='first'),
    output: targets['hub']
    run:
        from trackhub import Track, AggregateTrack, default_hub
        from trackhub.upload import upload_hub

        hub, genomes_file, genome, trackdb = default_hub(
            hub_name="hisat2",
            genome="dm6",
            short_label="Flybase example Hisat2",
            long_label="Flybase example Hisat2",
            email="justin.fear@nih.gov")

        # hub's location on remote host, for use with rsync
        hub.remote_fn = output[0]

        # publicly accessible hub URL
        hub.url = output[0].replace('/data/fearjm/datashare', 'http://helix.nih.gov/~fearjm')

        rx = re.compile(regex(patterns['bamCoverage']))
        for first in input.individual:
            second = first.replace('first', 'second')

            m = re.match(rx, first).groupdict()
            label = '{experiment}_{sample}'.format(**m)

            aggregate = AggregateTrack(
                name=label,
                autoScale='on',
                tracktype='bigWig',
                short_label=label,
                long_label=label,
                aggregate='transparentOverlay',
                showSubtrackColorOnUi='on',
            )

            # Parameters are checked for valid values, see
            l1 = label + '_first'
            track1 = Track(
                name=l1,
                short_label=l1,
                long_label=l1,
                local_fn=first,
                tracktype='bigWig',
                color="255,0,0"
                )

            l2 = label + '_second'
            track2 = Track(
                name=l2,
                short_label=l2,
                long_label=l2,
                local_fn=second,
                tracktype='bigWig',
                color="0,0,255"
                )

            aggregate.add_subtrack(track1)
            aggregate.add_subtrack(track2)
            trackdb.add_tracks(aggregate)

        # golden
        label = 'golden'
        first = input.golden
        second = first.replace('first', 'second')

        aggregate = AggregateTrack(
            name=label,
            autoScale='on',
            tracktype='bigWig',
            short_label=label,
            long_label=label,
            aggregate='transparentOverlay',
            showSubtrackColorOnUi='on',
        )

        # Parameters are checked for valid values, see
        l1 = label + '_first'
        track1 = Track(
            name=l1,
            short_label=l1,
            long_label=l1,
            local_fn=first,
            tracktype='bigWig',
            color="255,0,0"
            )

        l2 = label + '_second'
        track2 = Track(
            name=l2,
            short_label=l2,
            long_label=l2,
            local_fn=second,
            tracktype='bigWig',
            color="0,0,255"
            )

        aggregate.add_subtrack(track1)
        aggregate.add_subtrack(track2)
        trackdb.add_tracks(aggregate)

        # unannotated golden
        label = 'unannotated_golden'
        first = input.unannotated_golden
        second = first.replace('first', 'second')

        aggregate = AggregateTrack(
            name=label,
            autoScale='on',
            tracktype='bigWig',
            short_label=label,
            long_label=label,
            aggregate='transparentOverlay',
            showSubtrackColorOnUi='on',
        )

        # Parameters are checked for valid values, see
        l1 = label + '_first'
        track1 = Track(
            name=l1,
            short_label=l1,
            long_label=l1,
            local_fn=first,
            tracktype='bigWig',
            color="255,0,0"
            )

        l2 = label + '_second'
        track2 = Track(
            name=l2,
            short_label=l2,
            long_label=l2,
            local_fn=second,
            tracktype='bigWig',
            color="0,0,255"
            )

        aggregate.add_subtrack(track1)
        aggregate.add_subtrack(track2)
        trackdb.add_tracks(aggregate)


        # Render the hub to text files
        hub.render()

        # Upload the hub files and all the bigwig files using rsync.
        upload_hub(None, None, hub=hub)


rule make_tgz:
    input:
        targets['expBamCoverage_fb'] +
        targets['golden_fb'] +
        targets['unannotated_golden_fb']
    output: patterns['fb_tgz']
    shell: """
    TMP=`mktemp -d`
    for FILE in {input}; do
        cp $FILE $TMP/
    done;

    tar -czf {output[0]} -C $TMP .
    rm -r $TMP
    """



################################################################################
# quick and dirty
################################################################################
rule merge_jcount:
    input: targets['jcounts']
    output: patterns['jcount']
    shell:"""
    if [ -e {output[0]} ]; then
        rm {output[0]}
    fi

    for FILE in {input}; do
        cat $FILE >> {output[0]}
    done;
    """
