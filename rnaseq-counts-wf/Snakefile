"""RNA-Seq Alignment workflow.

"""
import os
import sys
from pathlib import Path

import numpy as np
from more_itertools import chunked, flatten

sys.path.insert(0, "../src")
from ncbi_remap.queue import Queue


# Setup tempdir to work with lscratch
if os.getenv("SLURM_JOBID"):
    TMPDIR = os.path.join('/lscratch', os.getenv('SLURM_JOBID'))
else:
    TMPDIR = os.getenv('TMPDIR', "/tmp")
shell.prefix("set -euo pipefail; export TMPDIR={};".format(TMPDIR))

singularity: "../singularity/drosSRA_workflow.sif"
configfile: '../config/reference_config.yaml'

###############################################################################
# Set up file naming patterns and targets
###############################################################################
queue = Queue(
    targets="../output/rnaseq-wf/done.txt",
    subset="../output/prealn-wf/done.txt",
    completed="../output/rnaseq-counts-wf/done.txt",
    srx2srr="../output/srx2srr.csv",
    size=100,
)

chunks = {str(i): chunk for i, chunk in enumerate(chunked(queue.srxs, 50), 1)}

localrules: run_all

# If Dry-Run print queue
if any([x == "-n" for x in sys.argv]):
    print(queue)

###############################################################################
# Resources
###############################################################################
THREADS = 4
MEM = 4
LSCRATCH = 200
TIME = 4

###############################################################################
# Rules
###############################################################################
rule run_all:
    input: "../output/rnaseq-counts-wf/done.txt"


def expand_bams(wildcards):
    return [
        expand("../output/rnaseq-wf/bams/{srx}/{srx}.bam", srx=srx)[0]
        for srx in chunks[wildcards.i]
    ]


def expand_layouts(wildcards):
    return [
        queue.expand("../output/fastq-wf/layout/{srr}.parquet", srx)[0]
        for srx in chunks[wildcards.i]
    ]


def expand_strands(wildcards):
    return [
        queue.expand("../output/prealn-wf/strand/{srr}.parquet", srx)[0]
        for srx in chunks[wildcards.i]
    ]


rule featurecounts:
    input:
        genic="../lcdb-references/dmel/r6-11/gtf/dmel_r6-11.gtf",
        intergenic="../output/dmel_r6-11.intergenic.gtf",
        fusion="../output/nonstranded_exon_fusions.gtf",
        segment="../output/nonstranded_exon_segments.gtf",
        bams=expand_bams,
        layouts=expand_layouts,
        strands=expand_strands,
    output:
        done_flag="../output/rnaseq-counts-wf/done/group_{i}.txt"
    threads: THREADS
    resources:
        mem_gb=MEM,
        time_hr=TIME,
        lscratch=LSCRATCH,
    script:
        "scripts/grouped_featurecounts.py"

rule srx_complete:
    input: expand("../output/rnaseq-counts-wf/done/group_{i}.txt", i=chunks.keys())
    output: "../output/rnaseq-counts-wf/done.txt"
    shell:
        """
        for FILE in {input}; do
            cat $FILE >> {output}
        done
        """