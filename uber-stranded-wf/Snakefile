"""Aggregated BigWig of extremely well stranded files.

"""

# Setup tempdir to work with lscratch
TMPDIR = os.path.join('/lscratch', os.getenv('SLURM_JOBID'))
shell.prefix("set -euo pipefail; export TMPDIR={};".format(TMPDIR))

# Set working dir
workdir: '.'

# import config
configfile: '../config/reference_config.yaml'

patterns = {
    'bam': '../output/aln-wf/samples/{srx}/{srx}.bam',
}

subworkflow metadata:
    workdir: '../metadata-wf'
    snakefile: '../metadata-wf/Snakefile'


subworkflow quality:
    workdir: '../quality-wf'
    snakefile: '../quality-wf/Snakefile'


rule targets:
    input:
        '../output/uber-stranded-wf/uber_srxs.txt',
        '../output/uber-stranded-wf/uber_stranded.plus_sum.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_sum.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_max.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_max.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_median.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_median.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_mean.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_mean.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_75.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_75.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_95.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_95.bw',
        '../output/uber-stranded-wf/uber_stranded_merged.bam'
#         '../output/uber-stranded-wf/uber_stranded.plus_scaled.bw',
#         '../output/uber-stranded-wf/uber_stranded.minus_scaled.bw',
#         '../output/uber-stranded-wf/uber_stranded.plus_scaled_threshold1.bw',
#         '../output/uber-stranded-wf/uber_stranded.minus_scaled_threshold1.bw',
#         '../output/uber-stranded-wf/uber_stranded.plus_scaled_threshold10.bw',
#         '../output/uber-stranded-wf/uber_stranded.minus_scaled_threshold10.bw',


rule uber_srxs:
    input:
        libstrat=metadata('../output/metadata-wf/random_forest_library_strategy.parquet'),
        quality=quality('../output/quality-wf/rnaseq_srx_quality_ranks.tsv'),
    output: '../output/uber-stranded-wf/uber_srxs.txt'
    params:
        strand_cutoff=.99,
        quality_cutoff=60,
    script: 'scripts/uber_srxs.py'


def _bigWigMerge(wildcards):
    if wildcards['strand'] == 'plus':
        strand = 'first'
    else:
        strand = 'second'

    with open('../output/uber-stranded-wf/uber_srxs.txt') as fh:
        srxs = fh.read().strip().split('\n')

    files = []
    for srx in srxs:
        files.append(f'../output/aln-wf/samples/{srx}/{srx}.flybase.{strand}.bw')

    return files


rule bigWigMerge:
    input:
        srxs=rules.uber_srxs.output[0],
        fnames=_bigWigMerge,
        chromsizes='../output/dmel_r6-11.flybase.chromsizes'
    output: '../output/uber-stranded-wf/uber_stranded.{strand,plus|minus}_{agg_func,sum|mean|median|max|75|95}.bw'
    threads: 8
    shell: """
        bigWigMerge \
            --input {input.fnames} \
            --output {output[0]} \
            --chromSizes {input.chromsizes} \
            --threads {threads} \
            --agg {wildcards.agg_func}
    """


rule bigWigMerge_scale:
    input:
        srxs=rules.uber_srxs.output[0],
        fnames=_bigWigMerge,
        chromsizes='../output/dmel_r6-11.flybase.chromsizes'
    output: '../output/uber-stranded-wf/uber_stranded.{strand,plus|minus}_scaled.bw'
    threads: 8
    shell: """
        bigWigMerge \
            --input {input.fnames} \
            --output {output[0]} \
            --chromSizes {input.chromsizes} \
            --threads {threads} \
            --scale \
            --region X:0-23,542,271
    """


rule bigWigMerge_scale_theshold:
    input:
        srxs=rules.uber_srxs.output[0],
        fnames=_bigWigMerge,
        chromsizes='../output/dmel_r6-11.flybase.chromsizes'
    output: '../output/uber-stranded-wf/uber_stranded.{strand,plus|minus}_scaled_threshold1.bw'
    threads: 8
    shell: """
        bigWigMerge \
            --input {input.fnames} \
            --output {output[0]} \
            --chromSizes {input.chromsizes} \
            --threads {threads} \
            --scale \
            --threshold 1 \
            --region X:0-23,542,271
    """


rule bigWigMerge_scale_theshold10:
    input:
        srxs=rules.uber_srxs.output[0],
        fnames=_bigWigMerge,
        chromsizes='../output/dmel_r6-11.flybase.chromsizes'
    output: '../output/uber-stranded-wf/uber_stranded.{strand,plus|minus}_scaled_threshold10.bw'
    threads: 8
    shell: """
        bigWigMerge \
            --input {input.fnames} \
            --output {output[0]} \
            --chromSizes {input.chromsizes} \
            --threads {threads} \
            --scale \
            --threshold 10 \
            --region X:0-23,542,271
    """


def _get_uber_srxs():
    with open('../output/uber-stranded-wf/uber_srxs.txt') as fh:
        srxs = fh.read().strip().split('\n')

    return srxs


rule mergeBam:
    """Merge a large number of bams together."""
    input: expand(patterns['bam'], srx=_get_uber_srxs())
    output: '../output/uber-stranded-wf/uber_stranded_merged.bam'
    threads: 12
    script: 'scripts/merge_bam.py'


rule stringTie_merged:
    """Create a StringTie GTF from a merged set of BAMs.

    This should get around any coverage issues, but differences in
    strandedness may cause problems.
    """
    input:
        bam = rules.bamMerge.output[0],
        gtf = config['references']['dmel']['gtf'],
    output: '../output/uber-stranded-wf/uber_stranded_merged.stringtie.gtf'
    threads: 2
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 1,
      time_hr=lambda wildcards, attempt: attempt * 1
    script: 'scripts/stringtie.py'
