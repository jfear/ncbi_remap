"""Aggregated BigWig of extremely well stranded files.

"""

subworkflow metadata:
    workdir: '../metadata-wf'
    snakefile: '../metadata-wf/Snakefile'


subworkflow quality:
    workdir: '../quality-wf'
    snakefile: '../quality-wf/Snakefile'


rule targets:
    input:
        '../output/uber-stranded-wf/uber_srxs.txt',
        '../output/uber-stranded-wf/uber_stranded.plus_sum.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_sum.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_max.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_max.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_median.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_median.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_mean.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_mean.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_75.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_75.bw',
        '../output/uber-stranded-wf/uber_stranded.plus_95.bw',
        '../output/uber-stranded-wf/uber_stranded.minus_95.bw',
        '../output/uber-stranded-wf/uber_stranded_merged.bam'
#         '../output/uber-stranded-wf/uber_stranded.plus_scaled.bw',
#         '../output/uber-stranded-wf/uber_stranded.minus_scaled.bw',
#         '../output/uber-stranded-wf/uber_stranded.plus_scaled_threshold1.bw',
#         '../output/uber-stranded-wf/uber_stranded.minus_scaled_threshold1.bw',
#         '../output/uber-stranded-wf/uber_stranded.plus_scaled_threshold10.bw',
#         '../output/uber-stranded-wf/uber_stranded.minus_scaled_threshold10.bw',


rule uber_srxs:
    input:
        libstrat=metadata('../output/metadata-wf/random_forest_library_strategy.parquet'),
        quality=quality('../output/quality-wf/rnaseq_srx_quality_ranks.tsv'),
    output: '../output/uber-stranded-wf/uber_srxs.txt'
    params:
        strand_cutoff=.99,
        quality_cutoff=60,
    script: 'scripts/uber_srxs.py'


def _bigWigMerge(wildcards):
    if wildcards['strand'] == 'plus':
        strand = 'first'
    else:
        strand = 'second'

    with open('../output/uber-stranded-wf/uber_srxs.txt') as fh:
        srxs = fh.read().strip().split('\n')

    files = []
    for srx in srxs:
        files.append(f'../output/aln-wf/samples/{srx}/{srx}.flybase.{strand}.bw')

    return files


rule bigWigMerge:
    input:
        srxs=rules.uber_srxs.output[0],
        fnames=_bigWigMerge,
        chromsizes='../output/dmel_r6-11.flybase.chromsizes'
    output: '../output/uber-stranded-wf/uber_stranded.{strand,plus|minus}_{agg_func,sum|mean|median|max|75|95}.bw'
    threads: 8
    shell: """
        bigWigMerge \
            --input {input.fnames} \
            --output {output[0]} \
            --chromSizes {input.chromsizes} \
            --threads {threads} \
            --agg {wildcards.agg_func}
    """


rule bigWigMerge_scale:
    input:
        srxs=rules.uber_srxs.output[0],
        fnames=_bigWigMerge,
        chromsizes='../output/dmel_r6-11.flybase.chromsizes'
    output: '../output/uber-stranded-wf/uber_stranded.{strand,plus|minus}_scaled.bw'
    threads: 8
    shell: """
        bigWigMerge \
            --input {input.fnames} \
            --output {output[0]} \
            --chromSizes {input.chromsizes} \
            --threads {threads} \
            --scale \
            --region X:0-23,542,271
    """


rule bigWigMerge_scale_theshold:
    input:
        srxs=rules.uber_srxs.output[0],
        fnames=_bigWigMerge,
        chromsizes='../output/dmel_r6-11.flybase.chromsizes'
    output: '../output/uber-stranded-wf/uber_stranded.{strand,plus|minus}_scaled_threshold1.bw'
    threads: 8
    shell: """
        bigWigMerge \
            --input {input.fnames} \
            --output {output[0]} \
            --chromSizes {input.chromsizes} \
            --threads {threads} \
            --scale \
            --threshold 1 \
            --region X:0-23,542,271
    """


rule bigWigMerge_scale_theshold10:
    input:
        srxs=rules.uber_srxs.output[0],
        fnames=_bigWigMerge,
        chromsizes='../output/dmel_r6-11.flybase.chromsizes'
    output: '../output/uber-stranded-wf/uber_stranded.{strand,plus|minus}_scaled_threshold10.bw'
    threads: 8
    shell: """
        bigWigMerge \
            --input {input.fnames} \
            --output {output[0]} \
            --chromSizes {input.chromsizes} \
            --threads {threads} \
            --scale \
            --threshold 10 \
            --region X:0-23,542,271
    """


def _bamMergeList(wildcards):
    with open('../output/uber-stranded-wf/uber_srxs.txt') as fh:
        srxs = fh.read().strip().split('\n')

    files = []
    for srx in srxs:
        files.append(f'../output/aln-wf/samples/{srx}/{srx}.bam')

    return files


rule bamMergeList:
    input:
        srxs = rules.uber_srxs.output[0],
        fnames = _bamMergeList,
    output: '../output/uber-stranded-wf/uber_straned_bam_list.txt'
    run:
        with open(output[0], 'w') as fh:
            fh.write('\n'.join(input.fnames))


rule bamMerge:
    input: rules.bamMergeList.output[0]
    output: '../output/uber-stranded-wf/uber_stranded_merged.bam'
    shell: """
        samtools merge \
            -b {input[0]} \
            {output[0]}

    """
