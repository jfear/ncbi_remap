"""Create a feature set for machine learning.

Identify and munge a set of features from the files generated by the prealn-wf
and aln-wf.

Features include:
* CollectRNASeqMetrics
    * 'PCT_CODING_BASES',
    * 'PCT_UTR_BASES',
    * 'PCT_INTRONIC_BASES',
    * 'PCT_INTERGENIC_BASES',
    * 'PCT_MRNA_BASES',
    * 'MEDIAN_CV_COVERAGE',
    * 'MEDIAN_5PRIME_BIAS',
    * 'MEDIAN_3PRIME_BIAS'
* CollectRNASeqMetrics Gene Body Coverage
* Markduplicates
    * 'PERCENT_DUPLICATION',
* FeatureCounts Summary
    * 'Assigned',
    * 'Unassigned_Ambiguity',
    * 'Unassigned_MultiMapping',
    * 'Unassigned_NoFeatures',
    * 'Unassigned_Unmapped'
* FeatureCounts Coverage Counts
    * All Genes
    * All junctions in genes
    * All Intergenic regions
"""
import os
from pathlib import Path

import numpy as np
import pandas as pd


def main():
    # Connect to data store
    store = pd.HDFStore(snakemake.input[0], mode="r")

    # Generate a list of completed SRXs
    srxs = store["prealn/complete"].srx.unique().tolist()

    # CollectRNASeqMetrics
    cols = [
        "PCT_CODING_BASES",
        "PCT_UTR_BASES",
        "PCT_INTRONIC_BASES",
        "PCT_INTERGENIC_BASES",
        "PCT_MRNA_BASES",
        "MEDIAN_CV_COVERAGE",
        "MEDIAN_5PRIME_BIAS",
        "MEDIAN_3PRIME_BIAS",
    ]
    cm = (
        store.select(
            "prealn/workflow/collectrnaseqmetrics/unstranded", where="srx == srxs", columns=cols
        )
        .groupby("srx")
        .median()
    )

    # CollectRNASeqMetrics Gene Body Coverage
    gb = (
        store.select("prealn/workflow/collectrnaseqmetrics/genebody", where="srx == srxs")
        .groupby("srx")
        .median()
    )

    # Markduplicates
    cols = ["PERCENT_DUPLICATION"]
    mark = (
        store.select("prealn/workflow/markduplicates", where="srx == srxs", columns=cols)
        .groupby("srx")
        .median()
    )

    # FeatureCounts Summary
    cols = [
        "Assigned",
        "Unassigned_Ambiguity",
        "Unassigned_MultiMapping",
        "Unassigned_NoFeatures",
        "Unassigned_Unmapped",
    ]
    feature_summary = (
        store.select("prealn/workflow/feature_counts/summary", columns=cols, where="srx == srxs")
        .groupby("srx")
        .median()
    )

    pd.concat([cm, gb, mark, feature_summary], axis=1).isnull()

    # FeatureCount Coverage Counts
    genic_counts = aggregate_feature_counts(snakemake.params.genic_counts, srxs).rename(
        {"count": "num_genic_reads", "prop_on": "prop_genes_on"}, axis=1
    )

    junction_counts = (
        aggregate_feature_counts(snakemake.params.junction_counts, srxs)
        .drop("prop_on", axis=1)
        .rename({"count": "num_junction_reads"}, axis=1)
    )

    # Make final feature set aggregated to SRX
    features = pd.concat(
        [cm, gb, mark, feature_summary, genic_counts, junction_counts], axis=1, sort=False
    ).rename_axis("srx")

    features.to_parquet(snakemake.output[0])


def aggregate_feature_counts(count_dir: str, srxs: list) -> pd.DataFrame:
    return pd.concat(
        (
            read_feature_counts(pth)
            for pth in Path(count_dir).glob("*.parquet")
            if check_srx_in_list(pth, srxs)
        ),
        axis=0,
        sort=False,
    )


def read_feature_counts(file_name: Path) -> pd.DataFrame:
    return (
        pd.read_parquet(file_name)
        .groupby("srx")
        .agg({"count": "sum"})
        .assign(prop_on=lambda x: (x["count"] > 0).mean())
    )


def check_srx_in_list(file_name: Path, srxs: list) -> bool:
    if file_name.stem in srxs:
        return True


if __name__ == "__main__":
    if os.getenv("SNAKE_DEBUG", False):
        from ncbi_remap.debug import snakemake_debug

        snakemake = snakemake_debug(
            input="../../output/sra.h5",
            params=dict(
                genic_counts="../../output/prealn-wf/gene_counts",
                junction_counts="../../output/prealn-wf/junction_counts",
            ),
        )

    main()
