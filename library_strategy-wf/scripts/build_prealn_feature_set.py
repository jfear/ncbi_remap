"""Create a feature set for machine learning.

Identify and munge a set of features from the files generated by the prealn-wf
and aln-wf.

Features include:
* CollectRNASeqMetrics
    * PCT_CODING_BASES
    * PCT_UTR_BASES
    * PCT_INTRONIC_BASES
    * PCT_INTERGENIC_BASES
    * PCT_MRNA_BASES
    * MEDIAN_CV_COVERAGE
    * MEDIAN_5PRIME_BIAS
    * MEDIAN_3PRIME_BIAS
* CollectRNASeqMetrics Gene Body Coverage
* Markduplicates
    * PERCENT_DUPLICATION
* Fastq Screen
    * Percent reads mapping to rRNA.
* FeatureCounts 
    * Number of reads mapping to junction
"""
import os
from pathlib import Path

import pandas as pd


def main():
    # Connect to data store
    store = pd.HDFStore(snakemake.input[0], mode="r")

    # Generate a list of completed SRXs
    srxs = store["prealn/complete"].srx.unique().tolist()

    # CollectRNASeqMetrics
    cols = [
        "PCT_CODING_BASES",
        "PCT_UTR_BASES",
        "PCT_INTRONIC_BASES",
        "PCT_INTERGENIC_BASES",
        "PCT_MRNA_BASES",
        "MEDIAN_CV_COVERAGE",
        "MEDIAN_5PRIME_BIAS",
        "MEDIAN_3PRIME_BIAS",
    ]
    cm = (
        store.select(
            "prealn/workflow/collectrnaseqmetrics/unstranded", where="srx == srxs", columns=cols
        )
        .groupby("srx")
        .median()
    )

    # CollectRNASeqMetrics Gene Body Coverage
    gb = (
        store.select("prealn/workflow/collectrnaseqmetrics/genebody", where="srx == srxs")
        .groupby("srx")
        .median()
    )

    # Markduplicates
    cols = ["PERCENT_DUPLICATION"]
    mark = (
        store.select("prealn/workflow/markduplicates", where="srx == srxs", columns=cols)
        .groupby("srx")
        .median()
        .squeeze()
        .rename("PCT_DUPLICATION")
    )

    # rRNA from FastQ_screen
    cols = [
        "reference",
        "multiple_hits_multiple_libraries_count",
        "multiple_hits_one_library_count",
        "one_hit_multiple_libraries_count",
        "one_hit_one_library_count",
        "reads_processed_count",
        "unmapped_count",
    ]
    fq_screen = percent_ribosomal(
        store.select("prealn/workflow/fastq_screen", where="srx == srxs", columns=cols)
    )

    # FeatureCount Junction Coverage Counts
    junction_counts = aggregate_feature_counts(snakemake.params.junction_counts, srxs).rename(
        {"count": "num_junction_reads"}, axis=1
    )

    # Make final feature set aggregated to SRX
    features = pd.concat(
        [cm, gb, mark, fq_screen, junction_counts], axis=1, sort=False
    ).rename_axis("srx")
    features.to_parquet(snakemake.output[0])


def percent_ribosomal(df):
    ribo_reads = df.groupby(["srx", "reference"]).sum().loc[(slice(None), "rRNA"), :].droplevel(-1)
    return (
        (ribo_reads.multiple_hits_one_library_count + ribo_reads.one_hit_one_library_count)
        .div(ribo_reads.reads_processed_count)
        .mul(100)
        .rename("PCT_RIBOSOMAL_READS")
    )


def aggregate_feature_counts(count_dir: str, srxs: list) -> pd.DataFrame:
    return pd.concat(
        (
            read_feature_counts(pth)
            for pth in Path(count_dir).glob("*.parquet")
            if check_srx_in_list(pth, srxs)
        ),
        axis=0,
        sort=False,
    )


def read_feature_counts(file_name: Path) -> pd.DataFrame:
    return pd.read_parquet(file_name).groupby("srx").agg({"count": "sum"})


def check_srx_in_list(file_name: Path, srxs: list) -> bool:
    if file_name.stem in srxs:
        return True


if __name__ == "__main__":
    if os.getenv("SNAKE_DEBUG", False):
        from ncbi_remap.debug import snakemake_debug

        snakemake = snakemake_debug(
            input="../../output/sra.h5",
            params=dict(
                genic_counts="../../output/prealn-wf/gene_counts",
                junction_counts="../../output/prealn-wf/junction_counts",
            ),
        )

    main()
