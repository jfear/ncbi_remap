"""Create a feature set for machine learning.

Identify and munge a set of features from the files generated by the prealn-wf
and aln-wf.

Features include:
* CollectRNASeqMetrics
    * PCT_CODING_BASES
    * PCT_UTR_BASES
    * PCT_INTRONIC_BASES
    * PCT_INTERGENIC_BASES
    * PCT_MRNA_BASES
    * MEDIAN_CV_COVERAGE
    * MEDIAN_5PRIME_BIAS
    * MEDIAN_3PRIME_BIAS
* CollectRNASeqMetrics Gene Body Coverage
* Markduplicates
    * PERCENT_DUPLICATION
* Fastq Screen
    * Percent reads mapping to rRNA.
* FeatureCounts
    * Number of reads mapping to junction
"""
import os
from pathlib import Path
from multiprocessing import Pool

import pandas as pd

# NOTE: features commented out are being dropped because they are repetitive or not important.
FEATURE_AGG = {
    "libsize_R1": "sum",
    "avgLen_R1": "mean",
    "libsize_R2": "sum",
    "avgLen_R2": "mean",
    # "adapters_pct_reads_mapped": "mean",
    "dm6_pct_reads_mapped": "mean",
    # "ecoli_pct_reads_mapped": "mean",
    # "ercc_pct_reads_mapped": "mean",
    # "hg19_pct_reads_mapped": "mean",
    # "phix_pct_reads_mapped": "mean",
    "rRNA_pct_reads_mapped": "mean",
    # "wolbachia_pct_reads_mapped": "mean",
    # "yeast_pct_reads_mapped": "mean",
    # "total_processed": "sum",
    # "total_written": "sum",
    "too_short": "sum",
    # "num_reads": "sum",
    # "num_reads_paired": "sum",
    # "num_reads_unpaired": "sum",
    "num_concordant_reads_unaligned": "sum",
    "num_concordant_reads_uniquely_aligned": "sum",
    "num_concordant_multimappers": "sum",
    "num_discordant_reads_aligned": "sum",
    "num_unaligned": "sum",
    "num_uniquely_aligned": "sum",
    "num_multimappers": "sum",
    "per_alignment": "mean",
    "reads_MQ0": "sum",
    "average_quality": "mean",
    "insert_size_average": "mean",
    "insert_size_standard_deviation": "mean",
    "inward_oriented_pairs": "sum",
    "outward_oriented_pairs": "sum",
    "pairs_with_other_orientation": "sum",
    "pairs_on_different_chromosomes": "sum",
    "Percent Forward": "mean",
    "Percent Reverse": "mean",
    "percent_coding_bases": "mean",
    "percent_utr_bases": "mean",
    "percent_intronic_bases": "mean",
    "percent_intergenic_bases": "mean",
    "percent_mrna_bases": "mean",
    "median_cv_coverage": "mean",
    # "median_5prime_bias": "mean",
    # "median_3prime_bias": "mean",
    # "median_5prime_to_3prime_bias": "mean",
    "unpaired_reads_examined": "sum",
    "read_pairs_examined": "sum",
    "unpaired_read_duplicates": "sum",
    "read_pair_duplicates": "sum",
    "percent_duplication": "mean",
    "estimated_library_size": "sum",
    "number_genic_reads": "sum",
    "percent_genes_on": "mean",
    "number_junction_reads": "sum",
    "number_junctions_on": "sum",
    "gene_body_five_prime": "mean",
    "gene_body_middle": "mean",
    "gene_body_three_prime": "mean",
}


def main():
    pool = Pool(snakemake.threads)

    srx2srr = pd.read_csv(snakemake.input[0], index_col="srr")
    done = {pth.stem for pth in Path(snakemake.params.done).iterdir()}
    df = pd.concat(
        pool.map(pd.read_parquet, [v for k, v in snakemake.params.items() if k != "done"]),
        axis=1,
        sort=False,
    ).reindex(done)

    (
        df.join(srx2srr)
        .pipe(aggregate_gene_body_coverage)
        .groupby("srx")
        .agg(FEATURE_AGG)
        .to_parquet(snakemake.output[0])
    )


def aggregate_gene_body_coverage(df):
    """Sum gene body coverage to tertile.

    GBC is reported as a centile, with positions next to each other being
    highly correlated. For machine learning, I am aggregating these features
    into a tertiles (i.e., 5', middle, 3').
    """
    cols = [f"pos_{i}" for i in range(101)]
    five_prime, middle, three_prime = cols[:33], cols[33:68], cols[68:]
    return (
        df.assign(gene_body_five_prime=lambda x: x[five_prime].sum(axis=1))
        .assign(gene_body_middle=lambda x: x[middle].sum(axis=1))
        .assign(gene_body_three_prime=lambda x: x[three_prime].sum(axis=1))
        .drop(cols, axis=1)
    )


if __name__ == "__main__":
    if os.getenv("SNAKE_DEBUG", False):
        import sys

        sys.path.insert(0, "../../src")
        from ncbi_remap.debug import snakemake_debug

        snakemake = snakemake_debug(
            input="../../output/srx2srr_full.csv",
            threads=8,
            params=dict(
                libsize="../../output/fastq-wf/libsize",
                layout="../../output/fastq-wf/layout",
                fastq_screen="../../output/prealn-wf/fastq_screen",
                atropos="../../output/prealn-wf/atropos",
                hisat2="../../output/prealn-wf/hisat2",
                aln_stats="../../output/prealn-wf/aln_stats",
                rnaseqmetrics="../../output/prealn-wf/rnaseqmetrics",
                genebody_coverage="../../output/prealn-wf/genebody_coverage",
                strand="../../output/prealn-wf/strand",
                markduplicates="../../output/prealn-wf/markduplicates",
                count_summary="../../output/prealn-wf/count_summary",
                done="../../output/prealn-wf/done",
            ),
        )

    main()
