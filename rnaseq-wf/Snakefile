"""RNA-Seq Alignment workflow.

The goal of the RNA-Seq workflow is to use parameters determined in the
pre-alignment workflow and processing files. This workflow uses a queue in
`../output/sra.h5`. To update the queue you need to run `./aln-store.py queue update
-j 8`. The major file types output by the alignment workflow include:

* Strand specific BigWig tracks
* Gene level coverage counts and junction counts
* Intergenic coverage counts and junction counts

Rules
-----
targets
    create a list of desired output files
intergenic
    create an intergenic bed and gtf based on the flybase gtf
fastq_dump
    download fastq file from SRA, determine if the file is pair-end or
    single-end and count the number of reads and average read length
atropos
    trim illumina adapters and low quality bases (<20) from fastq file, remove
    reads that have fewer than 25 bp
hisat2_splice_site
    create set of splice sites using the flybase gtf
hisat2
    align reads to the flybase reference
hisat2_summary
    parse alignment log and determine if the alignment failed (<50% aligned)
expMerge
    merge bams (SRRs) to the library (SRX) level
feature_counts
    count the number of reads that overlap genic regions and junction counts
featurecounts_intergenic
    count the number of reads that overlap intergenic regions and junction
    counts
run_stats
    calculate basic stats with `samtools stats`, `samtools idxstats`, and
    `bamtools stats`
bamCoverage
    create strand specific coverage tracks (bedgraph) using deeptools
convertToFlybase
    convert bedgraph chromosome names (UCSC format) to flybase chromosome names
convertBedGraphToBigWig
    convert begraph to bigwig
"""

import os
import sys
from pathlib import Path
import re
import shutil

import numpy as np
import pandas as pd

sys.path.insert(0, "../src")
from ncbi_remap.queue import Queue
from ncbi_remap.snakemake import slack


# Setup tempdir to work with lscratch
if os.getenv("SLURM_JOBID"):
    TMPDIR = os.path.join('/lscratch', os.getenv('SLURM_JOBID'))
else:
    TMPDIR = os.getenv('TMPDIR', "/tmp")
shell.prefix("set -euo pipefail; export TMPDIR={};".format(TMPDIR))

singularity: "../singularity/drosSRA_workflow.sif"
configfile: '../config/reference_config.yaml'
onsuccess:
    print('All Finished')
    slack('rnaseq-wf: All Finished')
onerror:
    print('Something went wrong, you need to re-run')
    slack('rnaseq-wf: Something went wrong, you need to re-run') 

localrules: srx_complete

###############################################################################
# Set up file naming patterns and targets
###############################################################################
queue = Queue(
    targets="../output/prealn-wf/done.txt",
    subset="../output/library_strategy-wf/rnaseq_inliers.pkl",
    completed="../output/rnaseq-wf/done.txt",
    problems=[
        "../output/fastq-wf/download_bad",
        "../output/fastq-wf/abi_solid",
        "../output/rnaseq-wf/atropos_bad",
        "../output/rnaseq-wf/alignment_bad",
        "../output/rnaseq-wf/bigwig_bad",
    ],
    srx2srr="../output/srx2srr.csv",
    size=500
)

# If Dry-Run print queue
if any([x == "-n" for x in sys.argv]):
    print(queue)

###############################################################################
# Resources
###############################################################################
LIBSIZES = queue.srx2srr[["srr", "libsize"]].set_index("srr").squeeze()
THREADS = 4
def estimate_resources(wildcards):
    scale = np.floor(np.log10(LIBSIZES[wildcards.srr]))
    if scale <= 3:
        return dict(mem_gb=4, time_hr=1, lscratch=10)
    elif scale <= 6:
        return dict(mem_gb=4, time_hr=2, lscratch=25)
    elif scale <= 7:
        return dict(mem_gb=6, time_hr=4, lscratch=60)
    else:
        return dict(mem_gb=6, time_hr=16, lscratch=200)

def estimate_resources_mem(wildcards):
    return estimate_resources(wildcards)["mem_gb"]

def estimate_resources_time(wildcards):
    return estimate_resources(wildcards)["time_hr"]

def estimate_resources_lscratch(wildcards):
    return estimate_resources(wildcards)["lscratch"]

###############################################################################
# Rules
###############################################################################
rule run_all:
    input: expand("../output/rnaseq-wf/done/{srx}", srx=queue.srxs)

rule fastq_dump:
    output: 
        r1=temp("../output/fastq-wf/fastqs/{srr}_1.fastq.gz"),
        r2=temp("../output/fastq-wf/fastqs/{srr}_2.fastq.gz"),
        layout="../output/fastq-wf/layout/{srr}.parquet",
        summary="../output/fastq-wf/libsize/{srr}.parquet"
    log: "../output/fastq-wf/logs/{srr}.log"
    params:
        sra="../output/fastq-wf/sra_cache/{srr}.sra",
        download_bad="../output/fastq-wf/download_bad",
        abi_solid="../output/fastq-wf/abi_solid",
    group: "rnaseq-wf"
    threads: THREADS
    resources: 
        mem_gb=estimate_resources_mem,
        time_hr=estimate_resources_time,
        lscratch=estimate_resources_lscratch,
    script: "../fastq-wf/scripts/fastq_dump.py"

## Rules
include: "../fastq-wf/rules/download_fastq.smk"
include: "rules/atropos.smk"
include: "rules/align.smk"
include: "rules/merge.smk"
include: "rules/featurecounts.smk"
include: "rules/bedgraph.smk"
include: "rules/bigwig.smk"


###############################################################################
# What to keep
###############################################################################

rule srx_complete:
    input:
        lambda wildcards: queue.expand(rules.atropos_check.output[0], wildcards.srx),
        lambda wildcards: queue.expand(rules.hisat2_check.output[0], wildcards.srx),
        rules.bamMerge.output.bam,
        rules.aln_stats_summary.output[0],
        rules.parse_gene_count.output[0],
        rules.parse_junction_count.output[0],
        rules.parse_intergenic_count.output[0],
        rules.parse_segment_count.output[0],
        rules.parse_fusion_count.output[0],
        rules.bigwig_first.output[0],
        rules.bigwig_second.output[0],
        rules.flybase_bigwig_first.output[0],
        rules.flybase_bigwig_second.output[0],
    output: "../output/rnaseq-wf/done/{srx}"
    params:
        sample_id=lambda wildcards: wildcards.srx,
        sample_folder="../output/rnaseq-wf/samples/{srx}",
        done_queue="../output/rnaseq-wf/done.txt",
        srrs=lambda wildcards: queue.get_srrs(wildcards.srx),
    script: "../scripts/done_queue.py"
