"""RNA-Seq Alignment workflow.

The goal of the RNA-Seq workflow is to use parameters determined in the
pre-alignment workflow and processing files. This workflow uses a queue in
`../output/sra.h5`. To update the queue you need to run `./aln-store.py queue update
-j 8`. The major file types output by the alignment workflow include:

* Strand specific BigWig tracks
* Gene level coverage counts and junction counts
* Intergenic coverage counts and junction counts

Rules
-----
targets
    create a list of desired output files
intergenic
    create an intergenic bed and gtf based on the flybase gtf
fastq_dump
    download fastq file from SRA, determine if the file is pair-end or
    single-end and count the number of reads and average read length
atropos
    trim illumina adapters and low quality bases (<20) from fastq file, remove
    reads that have fewer than 25 bp
hisat2_splice_site
    create set of splice sites using the flybase gtf
hisat2
    align reads to the flybase reference
hisat2_summary
    parse alignment log and determine if the alignment failed (<50% aligned)
expMerge
    merge bams (SRRs) to the library (SRX) level
feature_counts
    count the number of reads that overlap genic regions and junction counts
featurecounts_intergenic
    count the number of reads that overlap intergenic regions and junction
    counts
run_stats
    calculate basic stats with `samtools stats`, `samtools idxstats`, and
    `bamtools stats`
bamCoverage
    create strand specific coverage tracks (bedgraph) using deeptools
convertToFlybase
    convert bedgraph chromosome names (UCSC format) to flybase chromosome names
convertBedGraphToBigWig
    convert begraph to bigwig
"""

import os
import sys
from pathlib import Path
import re

import numpy as np
import pandas as pd

sys.path.insert(0, "../src")
from ncbi_remap.queue import Queue
from ncbi_remap.snakemake import slack


# Setup tempdir to work with lscratch
if os.getenv("SLURM_JOBID"):
    TMPDIR = os.path.join('/lscratch', os.getenv('SLURM_JOBID'))
else:
    TMPDIR = os.getenv('TMPDIR', "/tmp")
shell.prefix("set -euo pipefail; export TMPDIR={};".format(TMPDIR))

singularity: "../singularity/drosSRA_workflow.sif"
configfile: '../config/reference_config.yaml'
onsuccess:
    print('All Finished')
    slack('rnaseq-wf: All Finished')
onerror:
    print('Something went wrong, you need to re-run')
    slack('rnaseq-wf: Something went wrong, you need to re-run') 

localrules: atropos_summary_agg, hisat2_summary_agg, srx_complete

###############################################################################
# Set up file naming patterns and targets
###############################################################################
queue = Queue(
    targets="../output/library_strategy-wf/rnaseq.pkl",
    completed="../output/rnaseq-wf/done",
    problems=[
        "../output/fastq-wf/download_bad",
        "../output/fastq-wf/abi_solid",
        "../output/prealn-wf/atropos_bad",
        "../output/prealn-wf/alignment_bad",
        "../output/rnaseq-wf/atropos_bad",
        "../output/rnaseq-wf/alignment_bad",
        "../output/rnaseq-wf/bigwig_bad",
    ],
    srx2srr="../output/srx2srr.csv",
    size=1_000
)

# If Dry-Run print queue
if any([x == "-n" for x in sys.argv]):
    print(queue)

rule run_all:
    input: expand("../output/rnaseq-wf/done/{srx}", srx=queue.srxs)

## Rules
include: "../fastq-wf/rules/download_fastq.smk"
include: "rules/atropos.smk"
include: "rules/align.smk"
include: "rules/merge.smk"


###############################################################################
# Feature Counts
###############################################################################
def _layout(wildcards):
    fill = {
        'srx': wildcards.srx,
        'srr': queue.get_srrs(wildcards.srx)[0]
    }
    return expand("../output/fastq-wf/fastq_info/{srr}/LAYOUT", **fill)[0]


def _strand(wildcards):
    fill = {
        'srx': wildcards.srx,
        'srr': queue.get_srrs(wildcards.srx)[0]
    }
    return expand("../output/prealn-wf/samples/{srx}/{srr}/STRAND", **fill)[0]


rule feature_counts:
    input:
        annotation=config['references']['dmel']['gtf'],
        bam=rules.expMerge.output.bam,
        layout=_layout,
        strand=_strand,
    output:
        counts="../output/rnaseq-wf/samples/{srx}/{srx}.bam.counts",
        jcounts="../output/rnaseq-wf/samples/{srx}/{srx}.bam.counts.jcounts",
        summary="../output/rnaseq-wf/samples/{srx}/{srx}.bam.counts.summary",
    params:
        extra_pe = '-p -P -C -J ',
        extra_se = '-J '
    threads: 8
    group: "featureCount"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 16,
      time_hr=lambda wildcards, attempt: (attempt ** 2) * 4
    log: "../output/rnaseq-wf/samples/{srx}/{srx}.bam.counts.log"
    conda: "conda.yaml"
    wrapper:
        wrapper_for('../wrappers/featurecounts')


rule feature_counts_intergenic:
    """
    Count reads in intergenic regions with featureCounts from the subread package
    """
    input:
        annotation=config['references']['dmel']['intergenic'],
        bam=rules.expMerge.output.bam,
        layout=_layout,
    output:
        counts="../output/rnaseq-wf/samples/{srx}/{srx}.bam.intergenic.counts",
        jcounts="../output/rnaseq-wf/samples/{srx}/{srx}.bam.intergenic.counts.jcounts",
        summary="../output/rnaseq-wf/samples/{srx}/{srx}.bam.intergenic.counts.summary",
    params:
        extra_pe = '-p -P -C -J -t gene ',
        extra_se = '-J -t gene '
    threads: 8
    group: "featureCount"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 16,
      time_hr=lambda wildcards, attempt: (attempt ** 2) * 4
    log: "../output/rnaseq-wf/samples/{srx}/{srx}.bam.intergenic.counts.log"
    conda: "conda.yaml"
    wrapper:
        wrapper_for('../wrappers/featurecounts')


rule feature_counts_segments:
    """
    Count reads in intergenic regions with featureCounts from the subread package
    """
    input:
        annotation=config['references']['dmel']['nonstranded_segments'],
        bam=rules.expMerge.output.bam,
        layout=_layout,
    output:
        counts="../output/rnaseq-wf/samples/{srx}/{srx}.bam.exon_segments.counts",
        jcounts="../output/rnaseq-wf/samples/{srx}/{srx}.bam.exon_segments.counts.jcounts",
        summary="../output/rnaseq-wf/samples/{srx}/{srx}.bam.exon_segments.counts.summary",
    params:
        extra_pe = '-p -P -C -J -t segment -g ID ',
        extra_se = '-J -t segment -g ID '
    threads: 8
    group: "featureCount"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 16,
      time_hr=lambda wildcards, attempt: (attempt ** 2) * 4
    log: "../output/rnaseq-wf/samples/{srx}/{srx}.bam.exon_segments.counts.log"
    conda: "conda.yaml"
    wrapper:
        wrapper_for('../wrappers/featurecounts')


rule feature_counts_fusions:
    """
    Count reads in intergenic regions with featureCounts from the subread package
    """
    input:
        annotation=config['references']['dmel']['nonstranded_fusions'],
        bam=rules.expMerge.output.bam,
        layout=_layout,
    output:
        counts="../output/rnaseq-wf/samples/{srx}/{srx}.bam.exon_fusions.counts",
        jcounts="../output/rnaseq-wf/samples/{srx}/{srx}.bam.exon_fusions.counts.jcounts",
        summary="../output/rnaseq-wf/samples/{srx}/{srx}.bam.exon_fusions.counts.summary",
    params:
        extra_pe = '-p -P -C -J -t fusion -g ID ',
        extra_se = '-J -t fusion -g ID '
    threads: 8
    group: "featureCount"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 16,
      time_hr=lambda wildcards, attempt: (attempt ** 2) * 4
    log: "../output/rnaseq-wf/samples/{srx}/{srx}.bam.exon_fusions.counts.log"
    conda: "conda.yaml"
    wrapper:
        wrapper_for('../wrappers/featurecounts')


###############################################################################
# Make BedGraphs
###############################################################################
bamCoverage_options = (
    '--outFileFormat bedgraph '
    '--binSize 1 '
    '--effectiveGenomeSize 129000000 '
    '--normalizeUsing RPGC '
    '--ignoreForNormalization chrX '
)

rule bamCoverage_first:
    input:
        bam=rules.expMerge.output.bam,
        bai=rules.expMerge.output.bai,
    output: temp('../output/rnaseq-wf/samples/{srx}/{srx}.first.bedgraph')
    params:
        extra=bamCoverage_options + '--filterRNAstrand forward'
    threads: 8
    group: "bamCoverage"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 16,
      time_hr=lambda wildcards, attempt: attempt * 4
    conda: "conda.yaml"
    wrapper:
        wrapper_for('wrappers/deeptools/bamCoverage')


rule bamCoverage_second:
    input:
        bam=rules.expMerge.output.bam,
        bai=rules.expMerge.output.bai,
    output: temp('../output/rnaseq-wf/samples/{srx}/{srx}.second.bedgraph')
    params:
        extra=bamCoverage_options + '--filterRNAstrand reverse'
    threads: 8
    group: "bamCoverage"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 16,
      time_hr=lambda wildcards, attempt: attempt * 4
    conda: "conda.yaml"
    wrapper:
        wrapper_for('wrappers/deeptools/bamCoverage')


rule convertToFlybase_first:
    input: rules.bamCoverage_first.output[0]
    output: temp("../output/rnaseq-wf/samples/{srx}/{srx}.flybase.first.bedgraph")
    conda: 'conda.yaml'
    group: "FlyBaseConvert"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 12,
      time_hr=lambda wildcards, attempt: attempt * 4
    script: "scripts/chrom_convert.py"


rule convertToFlybase_second:
    input: rules.bamCoverage_second.output[0]
    output: temp("../output/rnaseq-wf/samples/{srx}/{srx}.flybase.second.bedgraph")
    conda: 'conda.yaml'
    group: "FlyBaseConvert"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 12,
      time_hr=lambda wildcards, attempt: attempt * 4
    script: "scripts/chrom_convert.py"


###############################################################################
# Make BigWigs
###############################################################################
rule bigwig_first:
    input:
        bedgraph=rules.bamCoverage_first.output[0],
        chromSizes=config['references']['dmel']['chromSizes']
    output: "../output/rnaseq-wf/samples/{srx}/{srx}.first.bw"
    conda: 'ucsc.yaml'
    group: "BigWig"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 12,
      time_hr=lambda wildcards, attempt: attempt * 4
    shell:
        'tmpBg=`mktemp --suffix=.bedgraph` '
        '&& bedSort {input.bedgraph} $tmpBg '
        '&& bedGraphToBigWig $tmpBg {input.chromSizes} {output[0]} '
        '&& rm $tmpBg '


rule bigwig_second:
    input:
        bedgraph=rules.bamCoverage_second.output[0],
        chromSizes=config['references']['dmel']['chromSizes']
    output: "../output/rnaseq-wf/samples/{srx}/{srx}.second.bw"
    conda: 'ucsc.yaml'
    group: "BigWig"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 12,
      time_hr=lambda wildcards, attempt: attempt * 4
    shell:
        'tmpBg=`mktemp --suffix=.bedgraph` '
        '&& bedSort {input.bedgraph} $tmpBg '
        '&& bedGraphToBigWig $tmpBg {input.chromSizes} {output[0]} '
        '&& rm $tmpBg '


rule flybase_bigwig_first:
    input:
        bedgraph=rules.convertToFlybase_first.output[0],
        chromSizes=config['references']['dmel']['fb_chromSizes']
    output: "../output/rnaseq-wf/samples/{srx}/{srx}.flybase.first.bw"
    conda: 'ucsc.yaml'
    group: "FlyBaseBigWig"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 12,
      time_hr=lambda wildcards, attempt: attempt * 4
    shell:
        'tmpBg=`mktemp --suffix=.bedgraph` '
        '&& bedSort {input.bedgraph} $tmpBg '
        '&& bedGraphToBigWig $tmpBg {input.chromSizes} {output[0]} '
        '&& rm $tmpBg '


rule flybase_bigwig_second:
    input:
        bedgraph=rules.convertToFlybase_second.output[0],
        chromSizes=config['references']['dmel']['fb_chromSizes']
    output: "../output/rnaseq-wf/samples/{srx}/{srx}.flybase.second.bw"
    conda: 'ucsc.yaml'
    group: "FlyBaseBigWig"
    resources:
      mem_gb=lambda wildcards, attempt: attempt * 12,
      time_hr=lambda wildcards, attempt: attempt * 4
    shell:
        'tmpBg=`mktemp --suffix=.bedgraph` '
        '&& bedSort {input.bedgraph} $tmpBg '
        '&& bedGraphToBigWig $tmpBg {input.chromSizes} {output[0]} '
        '&& rm $tmpBg '


###############################################################################
# What to keep
###############################################################################
rule srx_complete:
    input:
        rules.atropos_summary_agg.output[0],
        rules.hisat2_summary_agg.output[0],
        rules.expMerge.output.bam,
        rules.feature_counts.output.counts,
        rules.feature_counts_intergenic.output.counts,
        rules.feature_counts_segments.output.counts,
        rules.feature_counts_fusions.output.counts,
        rules.run_stats.output.samtools_stats,
        rules.run_stats.output.samtools_idxstats,
        rules.run_stats.output.bamtools_stats,
        rules.bigwig_first.output[0],
        rules.bigwig_second.output[0],
        rules.flybase_bigwig_first.output[0],
        rules.flybase_bigwig_second.output[0],
    output: "../output/rnaseq-wf/done/{srx}"
    params:
        srrs=lambda wildcards: queue.get_srrs(wildcards.srx)
    run:
        Path(output[0]).touch()
        for srr in params.srrs:
            if Path(f"../output/fastq-wf/fastqs/{srr}_1.fastq").exists():
                Path(f"../output/fastq-wf/fastqs/{srr}_1.fastq").unlink()

            if Path(f"../output/fastq-wf/fastqs/{srr}_2.fastq").exists():
                Path(f"../output/fastq-wf/fastqs/{srr}_2.fastq").unlink()

            if Path(f"../output/fastq-wf/sra_cache/{srr}.sra").exists():
                Path(f"../output/fastq-wf/sra_cache/{srr}.sra").unlink()
