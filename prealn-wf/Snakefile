#/usr/bin/env python
# vim: set ft=python.snakemake
import os
import sys
import shutil as sh
import gzip

import pandas as pd
from pathlib import Path

from lcdblib.snakemake import helpers
from lcdblib.utils import utils

sys.path.insert(0, '../lib/python')
from ncbi_remap.snakemake import wrapper_for, put_flag


# Setup tempdir to work with lscratch
TMPDIR = os.path.join('/lscratch', os.getenv('SLURM_JOBID'))
shell.prefix("set -euo pipefail; export TMPDIR={};".format(TMPDIR))

# Set working dir
workdir: '.'

# import config
configfile: '../config/reference_config.yml'


################################################################################
# Build Sample Table
################################################################################
store = pd.HDFStore('../sra.h5', mode='r')
sample_table = store['prealn/queue'].head(2)
store.close()

################################################################################
# Set up file naming patterns
################################################################################
patterns = {
    'fastq': {
        'r1': 'output/samples/{srx}/{srr}/{srr}_1.fastq.gz',
        'r2': 'output/samples/{srx}/{srr}/{srr}_2.fastq.gz',
        'summary': 'output/samples/{srx}/{srr}/{srr}.fastq.tsv',
    },
    'layout': 'output/samples/{srx}/{srr}/LAYOUT',
    'fastq_screen': 'output/samples/{srx}/{srr}/{srr}_1.fastq_screen.txt',
    'fastqc': {
        'html': 'output/samples/{srx}/{srr}/{srr}_1.fastqc.html',
        'zip': 'output/samples/{srx}/{srr}/{srr}_1.fastqc.zip',
    },
    'atropos': {
        'r1': 'output/samples/{srx}/{srr}/{srr}_1.trim.clean.fastq.gz',
        'r2': 'output/samples/{srx}/{srr}/{srr}_2.trim.clean.fastq.gz',
    },
    'hisat2': {
        'splice_sites': 'output/known_splice_sites_r6-11.txt',
        'bam': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam',
        'summary': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.tsv',
    },
    'bai': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.bai',
    'feature_counts': {
        'counts': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.feature_counts.counts',
        'jcounts': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.feature_counts.counts.jcounts',
        'summary': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.feature_counts.counts.summary',
    },
    'picard': {
        'collectrnaseqmetrics': {
            'metrics': {
                'unstranded': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.NONE.picard.collectrnaseqmetrics',
                'first': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.FIRST_READ_TRANSCRIPTION_STRAND.picard.collectrnaseqmetrics',
                'second': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.SECOND_READ_TRANSCRIPTION_STRAND.picard.collectrnaseqmetrics',
            },
        },
        'markduplicates': {
            'bam': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.picard.markduplicates.bam',
            'metrics': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.picard.markduplicates.metrics',
        },
    },
    'strand': 'output/samples/{srx}/{srr}/STRAND',
    'samtools_stats': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.samtools.stats',
    'samtools_idxstats': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.samtools.idxstats',
    'bamtools_stats': 'output/samples/{srx}/{srr}/{srr}.hisat2.bam.bamtools.stats',
}


# Build target files
targets = helpers.fill_patterns(patterns, sample_table)

def keepers(targets):
    return [
        targets['fastq_screen'],
        targets['hisat2']['summary'],
        targets['feature_counts']['summary'],
        targets['samtools_stats'],
        targets['samtools_idxstats'],
        targets['bamtools_stats'],
        targets['picard']['markduplicates']['metrics']
    ]

rule targets:
    input: keepers(targets)


rule update_queue:
    run:
        def check(srx, srr, targets):
            for fname in utils.flatten(keepers(targets)):
                if not os.path.exists(fname):
                    return
            # TODO add bad alignment check
            return srx, srr

        done = []
        for i, row in sample_table.iterrows():
            srx, srr = row.srx, row.srr
            targets = helpers.fill_patterns(patterns, row)
            value = check(srx, srr, targets)
            if value is not None:
                done.append(value)
        print(done)

onsuccess:
    print('All Finished')


onerror:
    print('Something went wrong, you need to re-run')


################################################################################
# FASTQ dump and check for SE or PE
################################################################################
rule fastq_dump:
    """Downloads fastq and checks if there is one or two sets of reads."""
    output:
        fq1=patterns['fastq']['r1'],
        fq2=patterns['fastq']['r2'],
        flag=patterns['layout'],
        summary=patterns['fastq']['summary'],
    log: patterns['fastq']['r1'] + '.log'
    wrapper:
        wrapper_for('wrappers/fastq_dump')


################################################################################
# FASTQ QC
################################################################################
rule fastq_screen:
    """Check for contamination."""
    input:
        fastq=patterns['fastq']['r1'],
        dm6=config['references']['dmel']['bowtie2'],
        hg19=config['references']['human']['bowtie2'],
        wolbachia=config['references']['wolbachia']['bowtie2'],
        ecoli=config['references']['ecoli']['bowtie2'],
        yeast=config['references']['yeast']['bowtie2'],
        rRNA=config['references']['rRNA']['bowtie2'],
        phix=config['references']['phix']['bowtie2'],
        ercc=config['references']['ercc']['bowtie2'],
        adapters=config['references']['adapters']['bowtie2']
    output:
        txt=patterns['fastq_screen']
    log: patterns['fastq_screen'] + '.log'
    wrapper:
        wrapper_for('../lcdb-wf/wrappers/wrappers/fastq_screen')


################################################################################
# FASTQ Pre-process
################################################################################
rule atropos:
    """Filter reads that are less than 25bp."""
    input:
        R1=patterns['fastq']['r1'],
        R2=patterns['fastq']['r2'],
        layout=patterns['layout']
    output:
        R1=temp(patterns['atropos']['r1']),
        R2=temp(patterns['atropos']['r2']),
    params:
        extra_pe='-U 0 --minimum-length 25',
        extra_se='--minimum-length 25',
    log:
        patterns['atropos']['r1'] + '.log'
    threads: 8
    wrapper:
        wrapper_for('wrappers/atropos')


################################################################################
# Alignment
################################################################################
rule hisat2_splice_site:
    """Generate splicesite information from known annotations."""
    input:
        gtf=config['references']['dmel']['gtf']
    output: patterns['hisat2']['splice_sites']
    conda: "../config/extra_env.yaml"
    shell: "hisat2_extract_splice_sites.py {input.gtf} > {output}"


rule hisat2:
    """Basic alignment."""
    input:
        flag=patterns['layout'],
        index=config['references']['dmel']['hisat2'],
        splice_sites=patterns['hisat2']['splice_sites'],
        R1=patterns['atropos']['r1'],
        R2=patterns['atropos']['r2'],
        layout=patterns['layout']
    output:
        bam=temp(patterns['hisat2']['bam'])
    threads: 8
    params:
        hisat2_extra='--max-intronlen 300000 --known-splicesite-infile {splice}'.format(splice=patterns['hisat2']['splice_sites']),
        samtools_sort_extra='--threads 6 -l 9 -m 3G -T $TMPDIR/samtools_sort'
    log: patterns['hisat2']['bam'] + '.log'
    wrapper:
        wrapper_for('wrappers/hisat2/align')


rule hisat2_summary:
    """Parse log and flag as bad alignment if <50% aligned."""
    input:
        fn=patterns['hisat2']['bam']
    output: patterns['hisat2']['summary']
    run:
        from ncbi_remap.parser import parse_hisat2
        srr = wildcards.sample
        df = parse_hisat2(srr, input.fn + '.log')
        df.to_csv(output, sep='\t')

        if df.ix[0, 'per_alignment'] < .50:
            fname = os.path.join(os.path.dirname(output), 'ALIGNMENT_BAD')
            Path(fname).touch()


rule bai:
    input:
        bam='{prefix}.bam'
    output:
        bai=temp('{prefix}.bam.bai')
    conda: "../config/extra_env.yaml"
    shell:
        "samtools index {input.bam}"


################################################################################
# PICARD RNA Seq Metrics
################################################################################
rule collectrnaseqmetrics_unstrand:
    input:
        bam=rules.hisat2.output.bam,
        refflat=config['references']['dmel']['refflat']
    output:
        metrics=patterns['picard']['collectrnaseqmetrics']['metrics']['unstranded']
    params:
        extra='STRAND=NONE',
        java_args='-Xmx30g'
    log:
        patterns['picard']['collectrnaseqmetrics']['metrics']['unstranded'] + '.log'
    wrapper:
        wrapper_for('../lcdb-wf/wrappers/wrappers/picard/collectrnaseqmetrics')


rule collectrnaseqmetrics_first:
    input:
        bam=rules.hisat2.output.bam,
        refflat=config['references']['dmel']['refflat']
    output:
        metrics=patterns['picard']['collectrnaseqmetrics']['metrics']['first']
    params:
        extra='STRAND=FIRST_READ_TRANSCRIPTION_STRAND',
        java_args='-Xmx30g'
    log:
        patterns['picard']['collectrnaseqmetrics']['metrics']['first'] + '.log'
    wrapper:
        wrapper_for('../lcdb-wf/wrappers/wrappers/picard/collectrnaseqmetrics')


rule collectrnaseqmetrics_second:
    input:
        bam=rules.hisat2.output.bam,
        refflat=config['references']['dmel']['refflat']
    output:
        metrics=patterns['picard']['collectrnaseqmetrics']['metrics']['second']
    params:
        extra='STRAND=SECOND_READ_TRANSCRIPTION_STRAND',
        java_args='-Xmx30g'
    log:
        patterns['picard']['collectrnaseqmetrics']['metrics']['second'] + '.log'
    wrapper:
        wrapper_for('../lcdb-wf/wrappers/wrappers/picard/collectrnaseqmetrics')


rule collectrnaseqmetrics_agg:
    input:
        unstranded=patterns['picard']['collectrnaseqmetrics']['metrics']['unstranded'],
        first=patterns['picard']['collectrnaseqmetrics']['metrics']['first'],
        second=patterns['picard']['collectrnaseqmetrics']['metrics']['second'],
    output:
        flag=patterns['strand']
    run:
        from ncbi_remap.parser import parse_picardCollect_summary
        srr = wildcards.sample
        dfU = parse_picardCollect_summary(srr, input.unstranded)
        dfF = parse_picardCollect_summary(srr, input.first)
        dfS = parse_picardCollect_summary(srr, input.second)

        if dfF.PCT_CORRECT_STRAND_READS.values[0] >= .75:
            flag = 'same_strand'
        elif dfS.PCT_CORRECT_STRAND_READS.values[0] >= .75:
            flag = 'opposite_strand'
        else:
            flag = 'unstranded'

        put_flag(output.flag, flag)


################################################################################
# Feature Counts
################################################################################
rule feature_counts:
    input:
        annotation=config['references']['dmel']['gtf'],
        bam=patterns['hisat2']['bam'],
        layout=patterns['layout'],
        strand=patterns['strand'],
    output:
        counts=patterns['feature_counts']['counts'],
        jcounts=patterns['feature_counts']['jcounts'],
        summary=patterns['feature_counts']['summary']
    params:
        extra_pe = '-p -P -C -J ',
        extra_se = '-J '
    threads: 4
    log:
        patterns['feature_counts']['counts'] + '.log'
    wrapper:
        wrapper_for('wrappers/featurecounts')


################################################################################
# Stats
################################################################################
rule run_stats:
    input:
        bam=patterns['hisat2']['bam'],
        bai=patterns['bai'],
    output:
        samtools_stats=patterns['samtools_stats'],
        samtools_idxstats=patterns['samtools_idxstats'],
        bamtools_stats=patterns['bamtools_stats']
    conda: '../config/extra_env.yaml'
    shell:
        'BAM=$(mktemp --suffix=".bam") '
        '&& cp {input.bam} $BAM '
        '&& cp {input.bam}.bai $BAM.bai '
        '&& samtools stats $BAM > {output.samtools_stats} '
        '&& samtools idxstats $BAM > {output.samtools_idxstats} '
        '&& bamtools stats -in $BAM > {output.bamtools_stats} '
        '&& rm $BAM'


################################################################################
# PICARD RNA Seq Metrics
################################################################################
rule markduplicates:
    input:
        bam=rules.hisat2.output.bam
    output:
        bam=temp(patterns['picard']['markduplicates']['bam']),
        metrics=patterns['picard']['markduplicates']['metrics']
    params:
        java_args='-Xmx30g'
    log:
        patterns['picard']['markduplicates']['metrics'] + '.log'
    wrapper:
        wrapper_for('../lcdb-wf/wrappers/wrappers/picard/markduplicates')


# vim: set ft=snakemake.python
