{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID Files for FlyBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FlyBase has the following desires\n",
    "\n",
    "1. High Quality stranded RNAseq data from Dmel (SRA project).\n",
    "    * Minimally: the whole compressed set (if that is feasible)\n",
    "    * Next priority: embryonic stages\n",
    "    * Next priorities: testis, neural tissues\n",
    "    * Are there other specific compressed sets that look particularly good? If so, we would like them, as well.\n",
    "    \n",
    "Splitting out the stages is going to be the hardest part. To address this I need:\n",
    "\n",
    "1. List of high qualtiy samples\n",
    "2. ID which samples are tech reps\n",
    "3. Cluster samples to ID tissues\n",
    "4. Corresponding normalized coverage tracks. \n",
    "\n",
    "I think I have the QC worked out and the merging worked out, but I still need to finalize. Once I have this list I can start building bedgraphs, while I figure out the tissues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2017-12-14 \n",
      "Git hash: e87982c4731fad7c2e653c44bdac2b3c0b09a594\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project level imports\n",
    "sys.path.insert(0, '../lib')\n",
    "from ncbi_remap.notebook import Nb\n",
    "from ncbi_remap.plotting import make_figs\n",
    "from ncbi_remap.prealn_wf import srx_reproducibility_score\n",
    "\n",
    "# Setup notebook\n",
    "nbconfig = Nb.setup_notebook('flybase_files')\n",
    "\n",
    "# Turn on cache\n",
    "from joblib import Memory\n",
    "memory = Memory(cachedir=nbconfig.cache, verbose=0)\n",
    "\n",
    "# Connect to data store\n",
    "store = pd.HDFStore('../sra.h5', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "from ncbi_remap.prealn_wf import (LIBSIZE_CUTOFF, READLEN_CUTOFF, STRAND_CUTOFF1, \n",
    "    STRAND_CUTOFF2, UNALIGN_CUTOFF, CONTAMINATION_CUTOFF)\n",
    "\n",
    "READY_SAMPLES = store['prealn/complete']\n",
    "num_samples = READY_SAMPLES.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncbi_remap.prealn_wf import libsize, libsize_cnts\n",
    "ok = libsize(store, cutoff=LIBSIZE_CUTOFF)\n",
    "ok['flag_libsize_ok'] = True\n",
    "READY_SAMPLES = READY_SAMPLES.merge(ok, how='left', on=['srx', 'srr']).fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncbi_remap.prealn_wf import readlen\n",
    "ok = readlen(store, cutoff=READLEN_CUTOFF)\n",
    "ok['flag_readlen_ok'] = True\n",
    "READY_SAMPLES = READY_SAMPLES.merge(ok, how='left', on=['srx', 'srr']).fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stranded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncbi_remap.prealn_wf import strandedness\n",
    "fs, sc, un = strandedness(store, cutoff=STRAND_CUTOFF2)\n",
    "ok = pd.concat([fs, sc])\n",
    "ok['flag_stranded_ok'] = True\n",
    "READY_SAMPLES = READY_SAMPLES.merge(ok, how='left', on=['srx', 'srr']).fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncbi_remap.prealn_wf import mappability\n",
    "ok = mappability(store, cutoff=UNALIGN_CUTOFF)\n",
    "ok['flag_map_ok'] = True\n",
    "READY_SAMPLES = READY_SAMPLES.merge(ok, how='left', on=['srx', 'srr']).fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "OK = READY_SAMPLES.loc[(READY_SAMPLES.sum(axis=1) == 4), ['srx', 'srr']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5,069 samples that pass all QC metrics.\n"
     ]
    }
   ],
   "source": [
    "print('There are {:,} samples that pass all QC metrics.'.format(OK.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Technical Replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def calc_score(dat, method='spearman', multi='pairwise', TH=1, show_warn=True, **kwargs):\n",
    "    dfs = []\n",
    "    for srx, df in dat.groupby('srx'):\n",
    "        dfs.extend(srx_reproducibility_score(store, srx, srr=df.srr.values, method=method, multi=multi, TH=TH, show_warn=show_warn, **kwargs))\n",
    "    return pd.DataFrame(dfs, columns=['srx', 'srrs', method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4,591 SRX with a single SRR.\n",
      "There are 478 SRX with multiple SRRs.\n"
     ]
    }
   ],
   "source": [
    "# Which SRX only have 1 rep\n",
    "cnts = OK.groupby('srx').count()\n",
    "\n",
    "singletons = OK[OK.srx.isin(cnts[cnts.srr == 1].index)]\n",
    "print('There are {:,} SRX with a single SRR.'.format(singletons.shape[0]))\n",
    "\n",
    "multitons = OK[OK.srx.isin(cnts[cnts.srr > 1].index)]\n",
    "print('There are {:,} SRX with multiple SRRs.'.format(multitons.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 309 SRX with multiple SRRs that that have a Spearman correlation ≥0.9\n"
     ]
    }
   ],
   "source": [
    "# Only keep SRX with multiple SRRs if all SRRs have a Spearman correlation >= 0.9\n",
    "score = calc_score(multitons)\n",
    "min_scores = score.groupby('srx').spearman.min()\n",
    "multi_ok = multitons[multitons.srx.isin(min_scores[min_scores >= .9].index)]\n",
    "\n",
    "print('There are {:,} SRX with multiple SRRs that that have a Spearman correlation ≥0.9'.format(multi_ok.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "OK2 = pd.concat([singletons, multi_ok], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4,900 samples that passed all QC and have good SRRs.\n"
     ]
    }
   ],
   "source": [
    "print('There are {:,} samples that passed all QC and have good SRRs.'.format(OK2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Sample List to get running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "OK2[['srx', 'srr']].to_csv('../output/flybase_samples.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ncbi_remap]",
   "language": "python",
   "name": "conda-env-ncbi_remap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
