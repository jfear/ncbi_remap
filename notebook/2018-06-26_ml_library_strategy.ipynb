{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Library Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dask import dataframe as dd\n",
    "from dask import delayed\n",
    "from dask.distributed import Client\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Project level imports\n",
    "sys.path.insert(0, '../lib')\n",
    "from ncbi_remap.plotting import make_figs\n",
    "from ncbi_remap.normalization import cpm\n",
    "\n",
    "# Connect to data store\n",
    "store = pd.HDFStore('../sra.h5', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "try:\n",
    "    with open('../output/.mongodb_host', 'r') as fh:\n",
    "        host = fh.read().strip()\n",
    "except FileNotFoundError:\n",
    "    host = 'localhost'\n",
    "\n",
    "mongoClient = MongoClient(host=host, port=27017)\n",
    "db = mongoClient['sra']\n",
    "ncbi = db['ncbi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=cpus, memory_limit=mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42171\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>26.14 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:42171' processes=8 cores=8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daskClient = Client()\n",
    "daskClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = store['aln/complete'].srx.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26545"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(list(ncbi.aggregate([\n",
    "    {\n",
    "        '$match': {\n",
    "            '_id': {'$in': samples}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'srx': '$_id',\n",
    "            'label': '$sra.experiment.library_strategy'\n",
    "        }\n",
    "    }\n",
    "])))\n",
    "\n",
    "labels.set_index('srx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaseq = labels.query('label == \"RNA-Seq\"').index.unique().tolist()\n",
    "dnaseq = labels.query('label == \"WGS\"').index.unique().tolist()\n",
    "chipseq = labels.query('label == \"ChIP-Seq\"').index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13829, 1970, 3003)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rnaseq), len(dnaseq), len(chipseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junction count distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def read_juncs(srx):\n",
    "    chroms = ['chrX', 'chr2L', 'chr2R', 'chr3L', 'chr3R', 'chr4', 'chrY']\n",
    "    junc = pd.read_parquet(f'../aln-wf/output/junction_counts/{srx}.parquet')\n",
    "    dat = junc.query(f'Site1_chr == {chroms} & Site1_chr == Site2_chr')[['PrimaryGene', 'srx', 'count']]\n",
    "    dat.columns = ['FBgn', 'srx', 'count']\n",
    "    dat.dropna(inplace=True)\n",
    "    return dat.groupby(['FBgn', 'srx'])['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "_size = 2000\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(30, 20), sharey=True)\n",
    "\n",
    "# RNA-seq\n",
    "futures = daskClient.compute([read_juncs(x) for x in rnaseq[:_size]])\n",
    "juncs = pd.concat(daskClient.gather(futures))\n",
    "sns.boxplot(x='srx', y='count', data=juncs.reset_index(), showfliers=False, color='grey', ax=ax1)\n",
    "plt.setp(ax1.get_xticklabels(), visible=False);\n",
    "ax1.set_title(f'RNA-Seq: {_size} samples')\n",
    "\n",
    "# DNA-seq\n",
    "futures = daskClient.compute([read_juncs(x) for x in dnaseq[:_size]])\n",
    "juncs = pd.concat(daskClient.gather(futures))\n",
    "sns.boxplot(x='srx', y='count', data=juncs.reset_index(), showfliers=False, color='grey', ax=ax2)\n",
    "plt.setp(ax2.get_xticklabels(), visible=False);\n",
    "ax2.set_title(f'DNA-Seq: {_size} samples')\n",
    "\n",
    "# ChIP-seq\n",
    "futures = daskClient.compute([read_juncs(x) for x in chipseq[:_size]])\n",
    "juncs = pd.concat(daskClient.gather(futures))\n",
    "sns.boxplot(x='srx', y='count', data=juncs.reset_index(), showfliers=False, color='grey', ax=ax3)\n",
    "plt.setp(ax3.get_xticklabels(), visible=False)\n",
    "ax3.set_title(f'ChIP-Seq: {_size} samples');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized read counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def get_norm_counts(srx):\n",
    "    # Gene level counts\n",
    "    gene = pd.read_parquet(f'../aln-wf/output/gene_counts/{srx}.parquet').reset_index()[['FBgn', 'srx', 'count']]\n",
    "    gene['var_type'] = 'gene'\n",
    "\n",
    "    # junction level counts\n",
    "    chroms = ['chrX', 'chr2L', 'chr2R', 'chr3L', 'chr3R', 'chr4', 'chrY']\n",
    "    junc = pd.read_parquet(f'../aln-wf/output/junction_counts/{srx}.parquet')\n",
    "    junc = junc.query(f'Site1_chr == {chroms} & Site1_chr == Site2_chr')[['PrimaryGene', 'srx', 'count']]\n",
    "    junc.columns = ['FBgn', 'srx', 'count']\n",
    "    junc.dropna(inplace=True) \n",
    "    junc = junc.groupby(['FBgn', 'srx'])['count'].sum().reset_index()\n",
    "    junc['var_type'] = 'junction'\n",
    "\n",
    "    # intergenic counts\n",
    "    inter_annot = pd.read_csv('../output/dmel_r6-11.intergenic.bed', sep='\\t', header=None, names=['chrom', 'start', 'end', 'FBgn'], index_col='FBgn')\n",
    "    inter_names = inter_annot.query(f'chrom == {chroms}').index.unique().tolist()\n",
    "    inter = pd.read_parquet(f'../aln-wf/output/intergenic_counts/{srx}.parquet').query(f'FBgn == {inter_names}').reset_index()[['FBgn', 'srx', 'count']]\n",
    "    inter['var_type'] = 'intergenic'\n",
    "\n",
    "    # combine, normalize, aggregate\n",
    "    df = pd.concat([gene, junc, inter])\n",
    "    norm = cpm(df.set_index(['FBgn', 'srx', 'var_type']), log='log10').reset_index()\n",
    "    medians = norm.groupby(['srx', 'var_type']).median().unstack()\n",
    "    medians.columns = medians.columns.droplevel(0)\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = daskClient.compute([get_norm_counts(x) for x in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(daskClient.gather(futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "_dat = data.join(labels)\n",
    "for g, _dd in _dat.groupby('label'):\n",
    "    ax.scatter(_dd.gene, _dd.junction, _dd.intergenic, label=g)\n",
    "    \n",
    "ax.set_xlabel('gene')\n",
    "ax.set_ylabel('junction')\n",
    "ax.set_zlabel('intergenic')\n",
    "plt.legend(loc=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ncbi_remap]",
   "language": "python",
   "name": "conda-env-ncbi_remap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
